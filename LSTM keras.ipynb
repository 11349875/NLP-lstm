{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "651eb072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mx\\AppData\\Roaming\\Python\\Python37\\site-packages\\requests\\__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.4) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from tensorflow.python.client import device_lib\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "import requests\n",
    "from nltk.tokenize import word_tokenize\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f6c817",
   "metadata": {},
   "source": [
    "Only run this code if you have a GPU. This part of the code makes the code run on your GPU, I used the tensorflow-gpu version 1.15 for this to work. It's considerably faster using my GPU (NVIDIA GTX 1060 6GB), than my CPU. About ~5 times faster, depending on the dataset I use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8de405d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:27:00.0, compute capability: 6.1\n",
      "\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6089656556499622330\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5083824128\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 14756280457857581038\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:27:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d86a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9037f96e",
   "metadata": {},
   "source": [
    "Several different datasets I experimented on, they are listed from short to long. The shortest one takes a couple of seconds to train, the longest one can, depending on your computer, take hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aed777e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29088\n"
     ]
    }
   ],
   "source": [
    "with open('wikiped.txt', 'r') as file:\n",
    "    data = file.read().replace('\\n', '')\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ff03120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128866\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"jokes.csv\")\n",
    "data = ' '.join(df['Joke'].tolist()).replace(\"\\'\", \"\")\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6105f5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182066\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.gutenberg.org/files/46/46-0.txt\"\n",
    "book = requests.get(url)\n",
    "data = book.text\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "616a6cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "797205\n"
     ]
    }
   ],
   "source": [
    "url = \"http://gutenberg.org/files/1342/1342-0.txt\"\n",
    "book = requests.get(url)\n",
    "data = book.text\n",
    "data = data[2440:]\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be15dfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2396753\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.gutenberg.org/files/24869/24869-0.txt\"\n",
    "book = requests.get(url)\n",
    "data = book.text\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34c1147",
   "metadata": {},
   "source": [
    "Cleaning of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5627c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(dataset):\n",
    "\n",
    "    # remove whitespace\n",
    "    tokenized = word_tokenize(dataset)\n",
    "    dataset = \" \".join([token.strip() for token in tokenized])\n",
    "\n",
    "    # remove characters\n",
    "    dataset = re.sub(r\"[^\\w\\n]\", \" \", dataset)\n",
    "\n",
    "    # replace multiple whitespaces with single whitespace\n",
    "    dataset = re.sub(r\"\\s+\", \" \", dataset)\n",
    "    dataset = dataset.strip()\n",
    "\n",
    "    dataset = dataset.lower()\n",
    "    dataset = dataset.replace(\"Ã¢\", \"a\")\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "data = clean_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2b958e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123588\n",
      "what did the bartender say to the jumper cables you better not try to start anything dont you hate j\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(data[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ab50d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size:  4715\n"
     ]
    }
   ],
   "source": [
    "word_tokeniser = Tokenizer()\n",
    "word_tokeniser.fit_on_texts([data])\n",
    "words_embedding = word_tokeniser.texts_to_sequences([data])[0]\n",
    "vocab_size = len(word_tokeniser.word_index) + 1\n",
    "print(\"Vocabulary Size: \", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36f5bf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "seq_length = 4\n",
    "\n",
    "for i in range(seq_length, len(words_embedding)):\n",
    "    sequence = words_embedding[i-seq_length:i+1]\n",
    "    sequences.append(sequence)\n",
    "sequences = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2d30d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the sequence into data and target\n",
    "sequences = np.array(sequences)\n",
    "\n",
    "X = sequences[:80000,:-1]  # assign all but last words of a sequence to X\n",
    "y = sequences[:80000,-1]   # assign last word of each sequence to y\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "\n",
    "X = pad_sequences(X, maxlen=seq_length, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f93df7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 200, input_length = seq_length))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(LSTM(256))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24884138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24295/24295 [==============================] - 3s 113us/step - loss: 7.2301 - accuracy: 0.0495\n",
      "Epoch 2/100\n",
      "24295/24295 [==============================] - 2s 84us/step - loss: 6.6188 - accuracy: 0.0477\n",
      "Epoch 3/100\n",
      "24295/24295 [==============================] - 2s 86us/step - loss: 6.5019 - accuracy: 0.0510\n",
      "Epoch 4/100\n",
      "24295/24295 [==============================] - 2s 83us/step - loss: 6.3198 - accuracy: 0.0600\n",
      "Epoch 5/100\n",
      "24295/24295 [==============================] - 2s 84us/step - loss: 6.1203 - accuracy: 0.0895\n",
      "Epoch 6/100\n",
      "24295/24295 [==============================] - 2s 85us/step - loss: 5.9128 - accuracy: 0.1068\n",
      "Epoch 7/100\n",
      "24295/24295 [==============================] - 2s 85us/step - loss: 5.6845 - accuracy: 0.1184\n",
      "Epoch 8/100\n",
      "24295/24295 [==============================] - 2s 94us/step - loss: 5.4589 - accuracy: 0.1321\n",
      "Epoch 9/100\n",
      "24295/24295 [==============================] - 2s 96us/step - loss: 5.2385 - accuracy: 0.1458\n",
      "Epoch 10/100\n",
      "24295/24295 [==============================] - 2s 90us/step - loss: 5.0129 - accuracy: 0.1644\n",
      "Epoch 11/100\n",
      "24295/24295 [==============================] - 2s 87us/step - loss: 4.7791 - accuracy: 0.1830\n",
      "Epoch 12/100\n",
      "24295/24295 [==============================] - 2s 84us/step - loss: 4.5485 - accuracy: 0.2015\n",
      "Epoch 13/100\n",
      "24295/24295 [==============================] - 2s 85us/step - loss: 4.3234 - accuracy: 0.2232\n",
      "Epoch 14/100\n",
      "24295/24295 [==============================] - 2s 83us/step - loss: 4.0988 - accuracy: 0.2445\n",
      "Epoch 15/100\n",
      "24295/24295 [==============================] - 2s 83us/step - loss: 3.8849 - accuracy: 0.2703\n",
      "Epoch 16/100\n",
      "24295/24295 [==============================] - 2s 82us/step - loss: 3.6813 - accuracy: 0.2943\n",
      "Epoch 17/100\n",
      "24295/24295 [==============================] - 2s 83us/step - loss: 3.4825 - accuracy: 0.3195\n",
      "Epoch 18/100\n",
      "24295/24295 [==============================] - 2s 84us/step - loss: 3.2899 - accuracy: 0.3508\n",
      "Epoch 19/100\n",
      "24295/24295 [==============================] - 2s 85us/step - loss: 3.1060 - accuracy: 0.3817\n",
      "Epoch 20/100\n",
      "24295/24295 [==============================] - 2s 83us/step - loss: 2.9343 - accuracy: 0.4143\n",
      "Epoch 21/100\n",
      "24295/24295 [==============================] - 2s 84us/step - loss: 2.7667 - accuracy: 0.4466\n",
      "Epoch 22/100\n",
      "24295/24295 [==============================] - 2s 83us/step - loss: 2.6034 - accuracy: 0.4807\n",
      "Epoch 23/100\n",
      "24295/24295 [==============================] - 2s 84us/step - loss: 2.4420 - accuracy: 0.5170\n",
      "Epoch 24/100\n",
      "24295/24295 [==============================] - 2s 86us/step - loss: 2.2914 - accuracy: 0.5471\n",
      "Epoch 25/100\n",
      "24295/24295 [==============================] - 2s 85us/step - loss: 2.1509 - accuracy: 0.5777\n",
      "Epoch 26/100\n",
      "24295/24295 [==============================] - 2s 84us/step - loss: 2.0178 - accuracy: 0.6050\n",
      "Epoch 27/100\n",
      "24295/24295 [==============================] - 2s 83us/step - loss: 1.8898 - accuracy: 0.6283\n",
      "Epoch 28/100\n",
      "24295/24295 [==============================] - 2s 83us/step - loss: 1.7669 - accuracy: 0.6559\n",
      "Epoch 29/100\n",
      "24295/24295 [==============================] - 2s 83us/step - loss: 1.6543 - accuracy: 0.6778\n",
      "Epoch 30/100\n",
      "24295/24295 [==============================] - 2s 84us/step - loss: 1.5524 - accuracy: 0.6990\n",
      "Epoch 31/100\n",
      "24295/24295 [==============================] - 2s 84us/step - loss: 1.4540 - accuracy: 0.7203\n",
      "Epoch 32/100\n",
      "24295/24295 [==============================] - 2s 84us/step - loss: 1.3615 - accuracy: 0.7396\n",
      "Epoch 33/100\n",
      "24295/24295 [==============================] - 2s 84us/step - loss: 1.2719 - accuracy: 0.7595\n",
      "Epoch 34/100\n",
      "24295/24295 [==============================] - 2s 85us/step - loss: 1.1890 - accuracy: 0.7776\n",
      "Epoch 35/100\n",
      "24295/24295 [==============================] - 2s 85us/step - loss: 1.1152 - accuracy: 0.7938\n",
      "Epoch 36/100\n",
      "24295/24295 [==============================] - 2s 83us/step - loss: 1.0438 - accuracy: 0.8078\n",
      "Epoch 37/100\n",
      "24295/24295 [==============================] - 2s 83us/step - loss: 0.9790 - accuracy: 0.8207\n",
      "Epoch 38/100\n",
      "24295/24295 [==============================] - 2s 83us/step - loss: 0.9155 - accuracy: 0.8325\n",
      "Epoch 39/100\n",
      "24295/24295 [==============================] - 2s 84us/step - loss: 0.8533 - accuracy: 0.8474\n",
      "Epoch 40/100\n",
      "24295/24295 [==============================] - 2s 84us/step - loss: 0.7978 - accuracy: 0.8585\n",
      "Epoch 41/100\n",
      "24295/24295 [==============================] - 2s 84us/step - loss: 0.7488 - accuracy: 0.8674\n",
      "Epoch 42/100\n",
      "24295/24295 [==============================] - 2s 85us/step - loss: 0.7001 - accuracy: 0.8770\n",
      "Epoch 43/100\n",
      "24295/24295 [==============================] - 2s 83us/step - loss: 0.6569 - accuracy: 0.8848\n",
      "Epoch 44/100\n",
      "24295/24295 [==============================] - 2s 84us/step - loss: 0.6144 - accuracy: 0.8938\n",
      "Epoch 45/100\n",
      "24295/24295 [==============================] - 2s 83us/step - loss: 0.5768 - accuracy: 0.9009\n",
      "Epoch 46/100\n",
      "24295/24295 [==============================] - 2s 83us/step - loss: 0.5403 - accuracy: 0.9068\n",
      "Epoch 47/100\n",
      "24295/24295 [==============================] - 2s 83us/step - loss: 0.5051 - accuracy: 0.9125\n",
      "Epoch 48/100\n",
      "24295/24295 [==============================] - 2s 83us/step - loss: 0.4769 - accuracy: 0.9180\n",
      "Epoch 49/100\n",
      "24295/24295 [==============================] - 2s 85us/step - loss: 0.4521 - accuracy: 0.9222\n",
      "Epoch 50/100\n",
      "24295/24295 [==============================] - 2s 85us/step - loss: 0.4238 - accuracy: 0.9274 0s - loss: 0.4201 \n",
      "Epoch 51/100\n",
      "24295/24295 [==============================] - 2s 84us/step - loss: 0.3974 - accuracy: 0.9311\n",
      "Epoch 52/100\n",
      "24295/24295 [==============================] - 2s 84us/step - loss: 0.3738 - accuracy: 0.9345\n",
      "Epoch 53/100\n",
      "24295/24295 [==============================] - 2s 84us/step - loss: 0.3526 - accuracy: 0.9374\n",
      "Epoch 54/100\n",
      "24295/24295 [==============================] - 2s 86us/step - loss: 0.3357 - accuracy: 0.9397\n",
      "Epoch 55/100\n",
      "24295/24295 [==============================] - 2s 85us/step - loss: 0.3164 - accuracy: 0.9418\n",
      "Epoch 56/100\n",
      "24295/24295 [==============================] - 2s 84us/step - loss: 0.3008 - accuracy: 0.9453\n",
      "Epoch 57/100\n",
      "24295/24295 [==============================] - 2s 82us/step - loss: 0.2867 - accuracy: 0.9453\n",
      "Epoch 58/100\n",
      "24295/24295 [==============================] - 2s 83us/step - loss: 0.2729 - accuracy: 0.9471\n",
      "Epoch 59/100\n",
      "24295/24295 [==============================] - 2s 82us/step - loss: 0.2601 - accuracy: 0.9490\n",
      "Epoch 60/100\n",
      "24295/24295 [==============================] - 2s 83us/step - loss: 0.2483 - accuracy: 0.9495\n",
      "Epoch 61/100\n",
      "24295/24295 [==============================] - 2s 86us/step - loss: 0.2377 - accuracy: 0.9513\n",
      "Epoch 62/100\n",
      "24295/24295 [==============================] - 2s 86us/step - loss: 0.2298 - accuracy: 0.9504\n",
      "Epoch 63/100\n",
      "24295/24295 [==============================] - 2s 86us/step - loss: 0.2218 - accuracy: 0.9530\n",
      "Epoch 64/100\n",
      "24295/24295 [==============================] - 2s 86us/step - loss: 0.2141 - accuracy: 0.9518\n",
      "Epoch 65/100\n",
      "24295/24295 [==============================] - 2s 85us/step - loss: 0.2066 - accuracy: 0.9523\n",
      "Epoch 66/100\n",
      "24295/24295 [==============================] - 2s 86us/step - loss: 0.2022 - accuracy: 0.9543\n",
      "Epoch 67/100\n",
      "24295/24295 [==============================] - 2s 83us/step - loss: 0.1951 - accuracy: 0.9531\n",
      "Epoch 68/100\n",
      "24295/24295 [==============================] - 2s 84us/step - loss: 0.1902 - accuracy: 0.9539 0s - loss: 0.1880 - ac\n",
      "Epoch 69/100\n",
      "24295/24295 [==============================] - 2s 85us/step - loss: 0.1846 - accuracy: 0.9546\n",
      "Epoch 70/100\n",
      "24295/24295 [==============================] - 2s 84us/step - loss: 0.1801 - accuracy: 0.9547\n",
      "Epoch 71/100\n",
      "24295/24295 [==============================] - 2s 83us/step - loss: 0.1762 - accuracy: 0.9544\n",
      "Epoch 72/100\n",
      "24295/24295 [==============================] - 2s 83us/step - loss: 0.1777 - accuracy: 0.9548\n",
      "Epoch 73/100\n",
      "24295/24295 [==============================] - 2s 84us/step - loss: 0.1788 - accuracy: 0.9539\n",
      "Epoch 74/100\n",
      "24295/24295 [==============================] - 2s 82us/step - loss: 0.1804 - accuracy: 0.9532\n",
      "Epoch 75/100\n",
      "24295/24295 [==============================] - 2s 82us/step - loss: 0.1748 - accuracy: 0.9542\n",
      "Epoch 76/100\n",
      "24295/24295 [==============================] - 2s 82us/step - loss: 0.1702 - accuracy: 0.9556\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24295/24295 [==============================] - 2s 83us/step - loss: 0.1662 - accuracy: 0.9539\n",
      "Epoch 78/100\n",
      "24295/24295 [==============================] - 2s 83us/step - loss: 0.1585 - accuracy: 0.9552\n",
      "Epoch 79/100\n",
      "24295/24295 [==============================] - 2s 84us/step - loss: 0.1539 - accuracy: 0.9565\n",
      "Epoch 80/100\n",
      "24295/24295 [==============================] - 2s 84us/step - loss: 0.1499 - accuracy: 0.9563\n",
      "Epoch 81/100\n",
      "24295/24295 [==============================] - 2s 86us/step - loss: 0.1466 - accuracy: 0.9560\n",
      "Epoch 82/100\n",
      "24295/24295 [==============================] - 2s 85us/step - loss: 0.1445 - accuracy: 0.9561\n",
      "Epoch 83/100\n",
      "24295/24295 [==============================] - 2s 85us/step - loss: 0.1421 - accuracy: 0.9564\n",
      "Epoch 84/100\n",
      "24295/24295 [==============================] - 2s 84us/step - loss: 0.1405 - accuracy: 0.9565\n",
      "Epoch 85/100\n",
      "24295/24295 [==============================] - 2s 83us/step - loss: 0.1396 - accuracy: 0.9553\n",
      "Epoch 86/100\n",
      "24295/24295 [==============================] - 2s 84us/step - loss: 0.1374 - accuracy: 0.9566\n",
      "Epoch 87/100\n",
      "24295/24295 [==============================] - 2s 84us/step - loss: 0.1368 - accuracy: 0.9557\n",
      "Epoch 88/100\n",
      "24295/24295 [==============================] - 2s 86us/step - loss: 0.1348 - accuracy: 0.9565\n",
      "Epoch 89/100\n",
      "24295/24295 [==============================] - 2s 89us/step - loss: 0.1342 - accuracy: 0.9565\n",
      "Epoch 90/100\n",
      "24295/24295 [==============================] - 2s 83us/step - loss: 0.1336 - accuracy: 0.9560\n",
      "Epoch 91/100\n",
      "24295/24295 [==============================] - 2s 83us/step - loss: 0.1338 - accuracy: 0.9563\n",
      "Epoch 92/100\n",
      "24295/24295 [==============================] - 2s 88us/step - loss: 0.1352 - accuracy: 0.9549\n",
      "Epoch 93/100\n",
      "24295/24295 [==============================] - 2s 88us/step - loss: 0.1360 - accuracy: 0.9565\n",
      "Epoch 94/100\n",
      "24295/24295 [==============================] - 2s 87us/step - loss: 0.1419 - accuracy: 0.9545\n",
      "Epoch 95/100\n",
      "24295/24295 [==============================] - 2s 86us/step - loss: 0.1617 - accuracy: 0.9529\n",
      "Epoch 96/100\n",
      "24295/24295 [==============================] - 2s 88us/step - loss: 0.1949 - accuracy: 0.9460\n",
      "Epoch 97/100\n",
      "24295/24295 [==============================] - 2s 89us/step - loss: 0.2122 - accuracy: 0.9434\n",
      "Epoch 98/100\n",
      "24295/24295 [==============================] - 2s 89us/step - loss: 0.1845 - accuracy: 0.9476\n",
      "Epoch 99/100\n",
      "24295/24295 [==============================] - 2s 88us/step - loss: 0.1525 - accuracy: 0.9533\n",
      "Epoch 100/100\n",
      "24295/24295 [==============================] - 2s 86us/step - loss: 0.1346 - accuracy: 0.9553\n",
      "208.40813260000004\n"
     ]
    }
   ],
   "source": [
    "# The 'joke' database on GPU 154.4100482 seconds for 100 epochs seq length of 4.\n",
    "# The 'joke' database on CPU 439.003922 seconds for 100 epochs seq length of 4.\n",
    "\n",
    "start = timer()\n",
    "model.fit(X, y, epochs=100, verbose=1, batch_size=256)\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c0d5ea",
   "metadata": {},
   "source": [
    "Make predictions using this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e730a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_words(model, word_tokeniser, seq_length, text, n_words):\n",
    "    for x in range(n_words):\n",
    "        \n",
    "        # create word embeddings\n",
    "        words_embedding = word_tokeniser.texts_to_sequences([text])[0]\n",
    "\n",
    "        padded_words = pad_sequences([words_embedding], maxlen=seq_length, padding='pre')\n",
    "        # predict next word\n",
    "        prediction = model.predict_classes(padded_words, verbose=0)\n",
    "\n",
    "        print(sorted(model.predict(padded_words)[0], reverse=True)[0:5])\n",
    "\n",
    "        next_word = \"\"\n",
    "        for word, i in word_tokeniser.word_index.items():\n",
    "            if [i] == prediction:\n",
    "                next_word = word\n",
    "                break\n",
    "        text += \" \" + next_word\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196a07ec",
   "metadata": {},
   "source": [
    "Pride and Prejudice corpus results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae905114",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 10\n",
    "\n",
    "sentence = \"She is not going to go with the\"\n",
    "print(generate_words(model, word_tokeniser, seq_length, sentence, num_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1c3360",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 3\n",
    "\n",
    "sentence = \"though he was now only established as a\"\n",
    "print(generate_words(model, word_tokeniser, seq_length, sentence, num_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43d47cf",
   "metadata": {},
   "source": [
    "With the joke dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d468fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99969816, 0.00013802716, 3.401807e-05, 2.1994174e-05, 1.0524708e-05]\n",
      "[0.14637631, 0.08872764, 0.076186754, 0.07592414, 0.07235614]\n",
      "[0.95845836, 0.027531892, 0.006469008, 0.0015967618, 0.0011852373]\n",
      "[0.83456224, 0.12347429, 0.008342455, 0.0067857774, 0.0048906007]\n",
      "knock knock whos there control freak con\n"
     ]
    }
   ],
   "source": [
    "num_words = 4\n",
    "\n",
    "sentence = \"knock knock whos\"\n",
    "print(generate_words(model, word_tokeniser, seq_length, sentence, num_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1739fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1071028, 0.09037031, 0.07648724, 0.061399058, 0.053121354]\n",
      "[0.99192387, 0.0036045008, 0.0013025511, 0.00061749533, 0.00034863313]\n",
      "[0.907875, 0.07908155, 0.0082408, 0.0015342761, 0.00061145105]\n",
      "[0.99938524, 0.00010775592, 9.38089e-05, 6.510899e-05, 4.0031653e-05]\n",
      "What did the turkey say to the\n"
     ]
    }
   ],
   "source": [
    "num_words = 4\n",
    "\n",
    "sentence = \"What did the\"\n",
    "print(generate_words(model, word_tokeniser, seq_length, sentence, num_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3784235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def perplexity():\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "2**-((0.5* math.log(1,2))+(0.1* math.log(0.1,2))+(0.1* math.log(0.1,2))+(0.1* math.log(0.1,2))+(0.1* math.log(0.1,2))+(0.1* math.log(0.1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6238e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

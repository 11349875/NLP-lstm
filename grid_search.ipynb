{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "651eb072",
   "metadata": {
    "id": "651eb072"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from tensorflow.python.client import device_lib\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from timeit import default_timer as timer\n",
    "import math\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from keras.models import model_from_json\n",
    "import h5py\n",
    "import numpy as np\n",
    "import sentencepiece as spm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sentencepiece as sp\n",
    "random.seed(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f64fb336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98f5097c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "98f5097c",
    "outputId": "4ecf52d9-0490-4d0d-c6d2-e09eaf02c90a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6f7f71d",
   "metadata": {
    "id": "e6f7f71d"
   },
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor(model_file='book.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9da69efe",
   "metadata": {
    "id": "9da69efe"
   },
   "outputs": [],
   "source": [
    "with open(\"testbook.txt\") as handle:\n",
    "    sentences =  [l.strip() for l in handle.readlines()]\n",
    "    \n",
    "v = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bc9cfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2063\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bae6c44",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bae6c44",
    "outputId": "dd161996-8a3b-4278-bcbd-1be100db8441"
   },
   "outputs": [],
   "source": [
    "\n",
    "x = []\n",
    "\n",
    "for a in sentences:\n",
    "    if len(a.split()) > 2 and len(a.split()) < 70:\n",
    "        x.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cb15830",
   "metadata": {
    "id": "4cb15830"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399\n",
      "[44, 80, 77, 79, 394, 1724, 9, 61, 76, 961, 3, 48, 1391, 820, 605, 916, 390, 5, 935, 46, 34, 4, 559, 9, 83, 418, 83, 825, 45, 59, 873, 6, 25, 1278, 111, 59, 126, 1894, 914, 93, 1314]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "X1 = []\n",
    "y1 = []\n",
    "for sentence in x:\n",
    "    X.append(sp.encode(sentence))\n",
    "    \n",
    "for sentence in X:\n",
    "    y1.append(sentence[-1])\n",
    "    X1.append(sentence[0:-1])\n",
    "    \n",
    "print(y1[0])\n",
    "print(X1[0])\n",
    "    \n",
    "y = to_categorical(y1, num_classes=v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbf4f52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg EBook of A Christmas Carol, by Charles Dickens This eBook is for the use of anyone anywhere at no cost and with almost no restrictions whatso\n",
      "ever\n"
     ]
    }
   ],
   "source": [
    "print(sp.decode(X1[0]))\n",
    "print(sp.decode(y1[0]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "260c6ccc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "260c6ccc",
    "outputId": "6172aef3-1f37-4be9-cdde-e847ad7bbc58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405\n"
     ]
    }
   ],
   "source": [
    "max1 = 0\n",
    "for i in x:\n",
    "    if len(i) > max1:\n",
    "        max1 = len(i)\n",
    "print(max1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd1eb0e8",
   "metadata": {
    "id": "fd1eb0e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  914,   93, 1314],\n",
       "       [   0,    0,    0, ...,  354,    8,  553],\n",
       "       [   0,    0,    0, ...,    3,  152, 2604],\n",
       "       ...,\n",
       "       [   0,    0,    0, ..., 2046,   46,  968],\n",
       "       [   0,    0,    0, ...,   14,   13,  400],\n",
       "       [   0,    0,    0, ...,  318,  107,  577]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = []\n",
    "for XD in X1:\n",
    "    X2.append(pad_sequences([XD], maxlen=max1, padding='pre')[0])\n",
    "    \n",
    "X2 = np.asarray(X2)\n",
    "X = X2\n",
    "X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b7a732f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ..., 2862, 1566,   28],\n",
       "       [   0,    0,    0, ...,   51,  137,   12],\n",
       "       [   0,    0,    0, ...,   12,  114, 1169],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   24,  265,   65],\n",
       "       [   0,    0,    0, ...,   63,  219,   42],\n",
       "       [   0,    0,    0, ...,    0,  186,  140]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = list(zip(X, y))\n",
    "\n",
    "random.shuffle(c)\n",
    "\n",
    "X, y = zip(*c)\n",
    "\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b01a741",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e44880f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Poor Robin Crusoe, where have you been, Robin Crusoe\n",
      "'\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "u = 94\n",
    "\n",
    "for i in X_train[u][np.nonzero(X_train[u])[0][0]:]:\n",
    "    a.append(int(i))\n",
    "    \n",
    "    \n",
    "print(sp.decode(a))\n",
    "print(sp.decode(int(np.nonzero(y_train[u])[0][0])))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cdc5ec",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc22c84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras import backend as K\n",
    "import scipy\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from keras.callbacks import EarlyStopping\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0f93df7c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0f93df7c",
    "outputId": "8819af5b-c241-4030-c9c7-9c4cbb789f25"
   },
   "outputs": [],
   "source": [
    "def create_model(optimizer='adam'):\n",
    "    K.clear_session()\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(v, 200, input_length = max1, mask_zero=True))\n",
    "\n",
    "    \n",
    "    model.add(LSTM(512, return_sequences=True))\n",
    "    model.add(LSTM(512))\n",
    "\n",
    "    # output layer\n",
    "    model.add(Dense(v, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create param_grid which is a dictionary of parameters to test\n",
    "# only using single parameters right now to speed up the proces\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "# Add things to these lists to add parameters to be tested\n",
    "epochs = [10]\n",
    "batches = [128]\n",
    "optimizers = ['adam']\n",
    "\n",
    "param_grid = dict(optimizer=optimizers, epochs=epochs, batch_size=batches)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5487c85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dba40a0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "309.93455719947815\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "grid_result = grid.fit(X_test, y_test, callbacks=[early_stopping], validation_data=(X_test, y_test))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "33ca3bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.195815 using {'batch_size': 128, 'epochs': 10, 'optimizer': 'adam'}\n",
      "0.195815 (0.069754) with: {'batch_size': 128, 'epochs': 10, 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8df9457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(Xp, yp, model):\n",
    "    chance = 0\n",
    "    current_index = 0\n",
    "    batch_size = 205\n",
    "\n",
    "    for _ in range(50):\n",
    "        distributionList = model.predict(Xp[current_index:current_index + batch_size], batch_size)\n",
    "    \n",
    "        tempcount = current_index\n",
    "        for distribution in distributionList:\n",
    "            chance += math.log2(distribution[np.nonzero(yp[tempcount])[0][0]])\n",
    "            tempcount += 1\n",
    "            \n",
    "        current_index = current_index + batch_size \n",
    "    return 2**((-1/len(Xp))* chance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24884138",
   "metadata": {
    "id": "24884138",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_model(model, epochs, batch_size):\n",
    "\n",
    " # kernel_regularizer=tf.keras.regularizers.l1(0.01)\n",
    "    for i in range(30):\n",
    "        model.fit(X_train, y_train, epochs=1, verbose=1, batch_size=128)\n",
    "        print(\"Loss and accuracy on valid\")\n",
    "        print(model.evaluate(x=X_test, y=y_test, batch_size=128, verbose=0))\n",
    "        print(\"Perplexity:\")\n",
    "        print(perplexity(X_test, y_test, model))\n",
    "        model.save_weights(str(i) + \".h5\")\n",
    "        print(\"Saved model to disk\")\n",
    "        print(\"\")\n",
    "    return model\n",
    "\n",
    "model = train_model(model, 50, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96be5414",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"5 model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c0d5ea",
   "metadata": {
    "id": "09c0d5ea"
   },
   "source": [
    "Make predictions using this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e730a18",
   "metadata": {
    "id": "6e730a18"
   },
   "outputs": [],
   "source": [
    "def generate_words(model, text):\n",
    "    # create word embeddings\n",
    "    words_embedding = sp.encode(sentence)\n",
    "\n",
    "    padded_words = pad_sequences([words_embedding], maxlen=max1, padding='pre')\n",
    "    # predict next word\n",
    "    prediction = np.argmax(model.predict(padded_words), axis=-1)\n",
    "    print(sp.decode(int(prediction[0])))\n",
    "    print(sorted(model.predict(padded_words)[0], reverse=True)[0:5])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "83e76f1b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "83e76f1b",
    "outputId": "b8024bb9-d253-4480-f8b0-cd1ded2e9748"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the collection centers , toys will be taken to a warehouse at 198 Second street , where they will be repaired and made ready for\n",
      "it\n",
      "[0.077863425, 0.072056495, 0.056057617, 0.02283041, 0.015822673]\n"
     ]
    }
   ],
   "source": [
    "sentence = sp.decode([1054,    5,\n",
    "       1892,  637,    4,    3,    6,   10,   17,    4,   74,   18,    3,\n",
    "        621,   10,   11,  362,   23, 1894,   39,  300, 1909, 4165,  827,\n",
    "          3,    6,  172,   70,   74,   18, 3670,    8,    9,    3,  132,\n",
    "       1189,   24])\n",
    "print(sentence)\n",
    "generate_words(model, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2ab8ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('brownsent.txt', 'r') as file:\n",
    "    data = file.read().replace('\\n', '')\n",
    "\n",
    "data = data.split()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6958d4ac",
   "metadata": {
    "id": "6958d4ac",
    "outputId": "aefe423c-981d-480c-8790-1f5eef66700d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1582.812467959088"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def baseline_perplex(data):\n",
    "    distribution = defaultdict(int)\n",
    "    for word in data:\n",
    "        distribution[word] += 1\n",
    "        \n",
    "    probdistribution = []   \n",
    "    sumD = sum(distribution.values())\n",
    "    for num in list(distribution.values()):\n",
    "        probdistribution.append(num/sumD)\n",
    "        \n",
    "    count = 0\n",
    "    for key in distribution.keys():\n",
    "        distribution[key] = probdistribution[count]\n",
    "        count += 1\n",
    "\n",
    "    chance = 0\n",
    "    for i in range(len(y_train)):\n",
    "        chance += math.log2(distribution.get(y_train[i], (1/sumD)))\n",
    "    \n",
    "    return 2**((-1/len(y_train))* chance)\n",
    "\n",
    "\n",
    "baseline_perplex(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3784235c",
   "metadata": {
    "id": "3784235c",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226.9762551690742\n",
      "74.30903339385986\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(perplexity(X_test, y_test, model))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8ab9aaa",
   "metadata": {
    "id": "b8ab9aaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1 Final perplexity 250\n",
    "#2 Final perplexity 542\n",
    "#3 Final perplexity 1178\n",
    "# Running model too long makes it overfit, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facb06df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is obsolete (much slower), keeping it here for archive purposes.\n",
    "\n",
    "def perplexity1(Xp, yp):\n",
    "    chance = 0\n",
    "    for i in range(len(Xp)):   \n",
    "        wordprob = model.predict([[Xp[i]]])[0][np.nonzero(yp[i])[0][0]]\n",
    "        if wordprob != 0:\n",
    "            chance += math.log2(wordprob)\n",
    "        print(wordprob)\n",
    "    return 2**((-1/len(Xp))* chance)\n",
    "\n",
    "perplexity1(X_test[0:12], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe356e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

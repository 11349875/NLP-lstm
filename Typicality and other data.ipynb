{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95c1af30",
   "metadata": {
    "id": "651eb072"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.optimize import minimize\n",
    "import math\n",
    "import json\n",
    "from nltk import tokenize\n",
    "import collections\n",
    "import re\n",
    "import itertools\n",
    "import nltk\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel,\\\n",
    "        GenericLikelihoodModelResults\n",
    "\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "from scipy.special import zeta\n",
    "from scipy.stats import binom\n",
    "from scipy.special import zeta\n",
    "from scipy.misc import derivative\n",
    "from scipy.stats import mannwhitneyu\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import numpy.random as rand\n",
    "from scipy.special import zeta\n",
    "from scipy.misc import derivative\n",
    "from nltk import tokenize\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "lg = np.log10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cab62f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    text = text.lower()\n",
    "    chars_to_remove = \"[\\n]!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\n",
    "    tr = str.maketrans(\" \", \" \", chars_to_remove)\n",
    "    return text.translate(tr)\n",
    "\n",
    "\n",
    "def preprocess(corpus, sent = True):\n",
    "    if sent:\n",
    "        corpus = tokenize.sent_tokenize(corpus)\n",
    "        corpus = [remove_punctuation(sent).split() for sent in corpus]\n",
    "    else:\n",
    "        corpus = remove_punctuation(corpus).split()\n",
    "    return corpus\n",
    "\n",
    "def make_file(corp, multi = False, sent = True, pos = False):\n",
    "    if multi:\n",
    "        corpus = ''\n",
    "        for subcorp in corp:\n",
    "            corpus += subcorp\n",
    "    else:\n",
    "        corpus = corp\n",
    "        \n",
    "    if pos:\n",
    "        corpus = part_of_speech(corpus)\n",
    "    \n",
    "    else:\n",
    "        corpus = preprocess(corpus, sent = sent)\n",
    "    \n",
    "    return corpus\n",
    "\n",
    "def subsampling(corpus, k = 1000000, m = 10, sent = True):\n",
    "    n = len(corpus)\n",
    "    \n",
    "    sen_len = {}\n",
    "\n",
    "    \n",
    "    rank_corpera = []\n",
    "    freq_corpera = []\n",
    "\n",
    "    if sent:\n",
    "        for i in range(m):\n",
    "            used_rank = set()\n",
    "            used_freq = set()\n",
    "            rank_count = 0\n",
    "            freq_count = 0\n",
    "            rank_samples = []\n",
    "            freq_samples = []\n",
    "\n",
    "            while rank_count < k:\n",
    "                index = np.random.randint(n)\n",
    "                if index in used_rank:\n",
    "                    continue\n",
    "\n",
    "                rank_sample = corpus[index]\n",
    "                len_sample = len(rank_sample)\n",
    "\n",
    "                if len_sample == 0:\n",
    "                    continue\n",
    "\n",
    "                rank_samples += rank_sample\n",
    "                rank_count += len_sample\n",
    "\n",
    "                if len_sample not in sen_len and len_sample < 200:\n",
    "                    sen_len[len_sample] = 1\n",
    "                elif len_sample < 200:\n",
    "                    sen_len[len_sample] += 1\n",
    "\n",
    "\n",
    "                used_rank.add(index)\n",
    "\n",
    "            while freq_count < k:\n",
    "                index = np.random.randint(n)\n",
    "                if index in used_freq:\n",
    "                    continue\n",
    "                freq_sample = corpus[index]\n",
    "                len_sample = len(freq_sample)\n",
    "\n",
    "                if len_sample == 0:\n",
    "                    continue\n",
    "\n",
    "                freq_samples += freq_sample\n",
    "                freq_count += len_sample\n",
    "\n",
    "                if len_sample not in sen_len and len_sample < 200:\n",
    "                    sen_len[len_sample] = 1\n",
    "                elif len_sample < 200:\n",
    "                    sen_len[len_sample] += 1\n",
    "\n",
    "                used_freq.add(index)\n",
    "\n",
    "            rank_corpera.append(rank_samples)\n",
    "            freq_corpera.append(freq_samples)\n",
    "\n",
    "\n",
    "    else:\n",
    "        for i in range(m):\n",
    "            rank_samples = random.sample(corpus, k)\n",
    "            freq_samples = random.sample(corpus, k)\n",
    "            rank_corpera.append(rank_samples)\n",
    "            freq_corpera.append(freq_samples)\n",
    "\n",
    "    return rank_corpera, freq_corpera\n",
    "\n",
    "\n",
    "def calculate_freqs(freq_sents):\n",
    "    freq_dict = {}\n",
    "    for i, corpus in enumerate(freq_sents):\n",
    "        freq_dict[i] = collections.Counter(corpus)\n",
    "        \n",
    "    freqs_df = pd.DataFrame(freq_dict)\n",
    "    freqs_df = freqs_df.fillna(0)\n",
    "    \n",
    "    return freqs_df\n",
    "\n",
    "\n",
    "def ranks_freqs(freq_sents, rank_sents):\n",
    "    freqs_df = calculate_freqs(freq_sents)\n",
    "    freqs_df['Frequency'] = mean_freqs(freqs_df)\n",
    "    ranks_df = calculate_ranks(rank_sents)\n",
    "    ranks_df['Rank'] = mean_ranks(ranks_df)\n",
    "    \n",
    " \n",
    "    ranks_freqs_df = pd.concat([ranks_df, freqs_df], axis = 1)\n",
    "    ranks_freqs_df = ranks_freqs_df.dropna()\n",
    "\n",
    "    return ranks_freqs_df\n",
    "\n",
    "def mean_freqs(freqs_df):\n",
    "    return(freqs_df.mean(axis=1))\n",
    "\n",
    "def calculate_ranks(rank_sents):\n",
    "    ranks_dicts = {}\n",
    "    for i, corpus in enumerate(rank_sents):\n",
    "        freqs = collections.Counter(corpus)\n",
    "        ranks_dicts[i] = {w: r for r, (w, c) in enumerate(freqs.most_common(), 1)}\n",
    "        \n",
    "    ranks_df = pd.DataFrame(ranks_dicts)\n",
    "    for column in ranks_df:\n",
    "        min_rank = int(np.ceil(ranks_df[column].max() + 1))\n",
    "        nan_rows = ranks_df[ranks_df[column].isnull()]\n",
    "        num_nans = len(nan_rows)\n",
    "        nan_ranks = list(range(min_rank, min_rank+num_nans))\n",
    "        random.shuffle(nan_ranks)\n",
    "        ranks_df.loc[ranks_df[column].isnull(), column] = nan_ranks\n",
    "\n",
    "    return ranks_df\n",
    "\n",
    "def mean_ranks(ranks_df):\n",
    "    return ranks_df.mean(axis=1)\n",
    "\n",
    "class Mandelbrot(GenericLikelihoodModel):\n",
    "\n",
    "    def __init__(self, frequencies, ranks, **kwargs):\n",
    "        if not len(frequencies) == len(ranks):\n",
    "            raise ValueError(\"NOT THE SAME NUMBER OF RANKS AND FREQS!\")\n",
    "        \n",
    "        frequencies = np.asarray(frequencies)\n",
    "        ranks = np.asarray(ranks)\n",
    "        \n",
    "        self.n_obs = np.sum(frequencies)\n",
    "        \n",
    "        super().__init__(endog=frequencies, exog=ranks, **kwargs)\n",
    "        self.fit_result = None\n",
    "    \n",
    "\n",
    "    def prob(self, params, ranks=None, log=False):\n",
    "        if ranks is None:\n",
    "            ranks = self.exog\n",
    "        \n",
    "        alpha, beta = params\n",
    "        if log:\n",
    "            return -alpha*lg(beta+ranks) - lg(zeta(alpha, q=beta+1.))\n",
    "        else:\n",
    "            return ((beta + ranks)**(-alpha))/zeta(alpha, q=beta+1.)\n",
    "    \n",
    "    \n",
    "    def loglike(self, params):\n",
    "        rs = self.exog\n",
    "        fs = self.endog\n",
    "        alpha, beta = params\n",
    "\n",
    "        log_probs = -alpha*lg(beta+rs) - lg(zeta(alpha, q=beta+1.))\n",
    "        log_probs = log_probs.reshape(-1, )\n",
    "        return np.sum(fs * log_probs) - beta**5\n",
    "    \n",
    "    \n",
    "    def register_fit(self, fit_result, overwrite=False):\n",
    "        if not self.fit_result is None and not overwrite:\n",
    "            raise ValueError(\"A fit result is already registered and overwrite=False!\")\n",
    "            \n",
    "        self.fit_result = fit_result\n",
    "        self.optim_params = fit_result.params\n",
    "        self.pseudo_r_squared = self.pseudo_r_squared(self.optim_params)\n",
    "        self.SE, self.SE_relative = fit_result.bse, fit_result.bse/self.optim_params\n",
    "        self.BIC, self.BIC_relative = fit_result.bic,\\\n",
    "                            (-2*self.null_loglike())/fit_result.bic\n",
    "\n",
    "        return self.optim_params\n",
    "    \n",
    "    def print_result(self, string=False):\n",
    "        if self.fit_result is None:\n",
    "            raise ValueError(\"Register a fitting result first!\")\n",
    "\n",
    "        def format_x(x):\n",
    "            return float('{0:.3g}'.format(x))\n",
    "\n",
    "\n",
    "        s = \"=\"*50\n",
    "        s += \"\\n\" + \"MANDELBROT\"\n",
    "        s += \"\\n\" + \"  Optimal Parameters \" + str(tuple(map(format_x, self.optim_params)))\n",
    "        \n",
    "        s += \"\\n\" + \"  Standard Error [relative]: \" + str(tuple(map(format_x, self.SE))) +\\\n",
    "              \", [\" + str(tuple(map(format_x, self.SE_relative))) + \"]\"\n",
    "        \n",
    "        s += \"\\n\" + \"  Pseudo R^2: \" + str(format_x(self.pseudo_r_squared))\n",
    "        \n",
    "        s += \"\\n\" + \"  BIC [relative]: \" + str(format_x(self.BIC)) +\\\n",
    "              \", [\" + str(format_x(self.BIC_relative)) + \"]\"\n",
    "        s += \"\\n\" + \"=\"*50\n",
    "        \n",
    "        if string:\n",
    "            return s\n",
    "        \n",
    "        print(s)\n",
    "    \n",
    "    \n",
    "    def null_loglike(self, epsilon=1e-10):\n",
    "        return self.loglike((1.+epsilon, 0.0))\n",
    "    \n",
    "    def pseudo_r_squared(self, params):\n",
    "        return 1-self.loglike(params)/self.null_loglike()\n",
    "    \n",
    "    \n",
    "    def predict(self, params, ranks=None, freqs=True, n_obs=None, \n",
    "                correct_for_finite_domain=True):\n",
    "        if ranks is None:\n",
    "            ranks = self.exog\n",
    "        ranks = np.asarray(ranks)\n",
    "        \n",
    "        if n_obs is None:\n",
    "            n_obs = self.n_obs\n",
    "            \n",
    "        alpha, beta = params\n",
    "        pred_probs = self.prob(params, ranks=ranks, log=False)\n",
    "        \n",
    "        if correct_for_finite_domain:\n",
    "            if not freqs:\n",
    "                raise NotImplementedError(\"Correction for \"\\\n",
    "                                          \"finite domain not implemented with probabilities!\")\n",
    "            return pred_probs*(n_obs/np.sum(pred_probs))\n",
    "        \n",
    "        if freqs:\n",
    "            return n_obs*pred_probs\n",
    "        \n",
    "        return pred_probs\n",
    "\n",
    "def zipfs_law(df):\n",
    "    mandelbrot = Mandelbrot(df['Frequency'], df['Rank'])\n",
    "    mandelbrot_fit = mandelbrot.fit(start_params=np.asarray([1.0, 1.0]), # [1.0, 1.0]\n",
    "                                method=\"powell\", full_output=True, disp=0)\n",
    "    mandelbrot.register_fit(mandelbrot_fit)\n",
    "    mandelbrot.print_result()\n",
    "    \n",
    "    model_params = mandelbrot.optim_params\n",
    "    alpha, beta =  mandelbrot.optim_params\n",
    "    preds = mandelbrot.predict(model_params, df['Rank'])\n",
    "    df['Estimated frequency'] = preds\n",
    "    df['Rank (log)'] = np.log(df['Rank'])\n",
    "    df['Frequency (log)'] = np.log(df['Frequency'])\n",
    "    df['Estimated frequency (log)'] = np.log(df['Estimated frequency'])\n",
    "    df['Error'] = df['Frequency (log)'] - df['Estimated frequency (log)']\n",
    "    return mandelbrot, df\n",
    "\n",
    "def zipf_entropy(alpha, dx=1e-10):\n",
    "    if alpha <= 1.0:\n",
    "        raise ValueError(\"Entropy undefined for the given parameter:\\n\" + \n",
    "                         str(alpha))\n",
    "    return alpha*(-derivative(zeta, alpha, dx=dx))/zeta(alpha) + lg(zeta(alpha))\n",
    "\n",
    "def mandelbrot_entropy(alpha, beta, dx=1e-10):\n",
    "    if alpha <= 1.0 or beta <= 1.0:\n",
    "        raise ValueError(\"Entropy undefined for the given parameters:\\n\" + \n",
    "                         str(alpha) + \" and \" + str(beta))\n",
    "    zeta_b = lambda a: zeta(a, beta+1)\n",
    "    return alpha*(-derivative(zeta_b, alpha, dx=dx))/zeta_b(alpha) + lg(zeta_b(alpha))\n",
    "\n",
    "\n",
    "def neg_log_likelihood(zipf_model, ranks, freqs):\n",
    "    mle_params = zipf_model.optim_params\n",
    "    log_rank_probs = zipf_model.prob(params=mle_params, ranks=ranks, log=True)    \n",
    "    return -freqs*log_rank_probs\n",
    "    \n",
    "    \n",
    "def empirical_entropy(zipf_model, joint_rank_freqs):\n",
    "    rs = list(joint_rank_freqs[\"Rank\"])\n",
    "    fs = list(joint_rank_freqs[\"Frequency\"])\n",
    "    ranks = np.asarray(rs)\n",
    "    freqs = np.asarray(fs)\n",
    "    n = np.sum(freqs)\n",
    "    return (1/n)*np.sum(neg_log_likelihood(zipf_model, ranks, freqs))\n",
    "\n",
    "def typicality(zipf_model, joint_rank_freqs):\n",
    "    mle_params = zipf_model.optim_params\n",
    "    return mandelbrot_entropy(*mle_params) - empirical_entropy(zipf_model, joint_rank_freqs)\n",
    "\n",
    "k = 400000\n",
    "m = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49faaf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "MANDELBROT\n",
      "  Optimal Parameters (1.14, 3.84)\n",
      "  Standard Error [relative]: (0.000344, 0.0246), [(0.000303, 0.0064)]\n",
      "  Pseudo R^2: 0.654\n",
      "  BIC [relative]: 3670000.0, [2.89]\n",
      "==================================================\n",
      "6.115576226257691\n"
     ]
    }
   ],
   "source": [
    "# Calculates typicality of corpus\n",
    "\n",
    "# Change text to desired corpus\n",
    "text = '1000000_0_0'\n",
    "\n",
    "file = 'CLEAN_' + text + '.txt'\n",
    "path = 'data/' + text + '/'\n",
    "\n",
    "\n",
    "with open(path + file , encoding=\"utf8\") as handle:\n",
    "    test =  [l.strip() for l in handle.readlines()]\n",
    "    \n",
    "test1 = []\n",
    "for arg in test:\n",
    "    test1.append(arg + '.')\n",
    "    \n",
    "test = test1\n",
    "sep_corps = [make_file(corpus, multi = True) for corpus in test]\n",
    "\n",
    "sep_corps1 = []\n",
    "for x in sep_corps:\n",
    "    sep_corps1.append(x[0])\n",
    "len(sep_corps1)\n",
    "\n",
    "k = 400000\n",
    "m = 6\n",
    "\n",
    "rank_corpora, freq_corpora = subsampling(sep_corps1, k=k, m=m)\n",
    "ranks_freqs_df = ranks_freqs(rank_corpora, freq_corpora)\n",
    "mand, df = zipfs_law(ranks_freqs_df)\n",
    "typ = typicality(mand, ranks_freqs_df)\n",
    "print(typ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "406da22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226924"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ' '.join(test)\n",
    "word_tokeniser = Tokenizer()\n",
    "word_tokeniser.fit_on_texts([data])\n",
    "vocab_size = len(word_tokeniser.word_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2297637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
